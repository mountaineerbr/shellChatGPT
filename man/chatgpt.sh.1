'\" t
.\" Automatically generated by Pandoc 3.5
.\"
.TH "CHATGPT.SH" "1" "December 2025" "v0.125" "General Commands Manual"
.SH NAME
.PP
\ \ \ chatgpt.sh \-\- Wrapper for ChatGPT / STT / TTS
.SH SYNOPSIS
.PP
\ \ \ \f[B]chatgpt.sh\f[R]
[\f[CR]\-bb\f[R]|\f[CR]\-cc\f[R]|\f[CR]\-dd\f[R]|\f[CR]\-qq\f[R]]
[\f[CR]opt\f[R]..]
[\f[I]PROMPT\f[R]|\f[I]TEXT_FILE\f[R]|\f[I]PDF_FILE\f[R]]
.PD 0
.P
.PD
\ \ \ \f[B]chatgpt.sh\f[R] \f[CR]\-w\f[R] [\f[CR]opt\f[R]..]
[\f[I]AUDIO_FILE\f[R]|\f[I].\f[R]] [\f[I]LANG\f[R]] [\f[I]PROMPT\f[R]]
.PD 0
.P
.PD
\ \ \ \f[B]chatgpt.sh\f[R] \f[CR]\-W\f[R] [\f[CR]opt\f[R]..]
[\f[I]AUDIO_FILE\f[R]|\f[I].\f[R]] [\f[I]PROMPT\-EN\f[R]]
.PD 0
.P
.PD
\ \ \ \f[B]chatgpt.sh\f[R] \f[CR]\-z\f[R] [\f[CR]opt\f[R]..]
[\f[I]OUTFILE\f[R]|\f[I]FORMAT\f[R]|\f[I]\-\f[R]] [\f[I]VOICE\f[R]]
[\f[I]SPEED\f[R]] [\f[I]PROMPT\f[R]]
.PD 0
.P
.PD
\ \ \ \f[B]chatgpt.sh\f[R] \f[CR]\-bccWwz\f[R] [\f[CR]opt\f[R]..]
\-\- [\f[I]PROMPT\f[R]] \-\- [\f[I]stt_arg\f[R]..]
\-\- [\f[I]tts_arg\f[R]..]
.PP
\ \ \ \f[B]chatgpt.sh\f[R] \f[CR]\-l\f[R] [\f[I]MODEL\f[R]]
.PD 0
.P
.PD
\ \ \ \f[B]chatgpt.sh\f[R] \f[CR]\-TTT\f[R] [\-v]
[\f[CR]\-m\f[R][\f[I]MODEL\f[R]|\f[I]ENCODING\f[R]]]
[\f[I]INPUT\f[R]|\f[I]TEXT_FILE\f[R]|\f[I]PDF_FILE\f[R]]
.PD 0
.P
.PD
\ \ \ \f[B]chatgpt.sh\f[R] \f[CR]\-HPP\f[R]
[\f[CR]/\f[R]\f[I]HIST_NAME\f[R]|\f[I].\f[R]]
.PD 0
.P
.PD
\ \ \ \f[B]chatgpt.sh\f[R] \f[CR]\-HPw\f[R]
.SH DESCRIPTION
This script acts as a wrapper for ChatGPT, STT (Whisper), and TTS
endpoints from OpenAI.
Various service providers such as LocalAI, Ollama, Anthropic, Mistral
AI, GoogleAI, Groq AI, GitHub Models, OpenRouter, xAI, and DeepSeek APIs
are supported.
.PP
By default, the script runs in single\-turn of chat completion mode,
processing INPUT directly when no options are set.
.PP
Handles single\-turn and multi\-turn modes, pure text and native chat
completions, speech\-to\-text, and text\-to\-speech models.
.PP
Positional arguments are read as a single PROMPT.
Some functions such as Whisper (STT) and TTS may handle optional
positional parameters before the text prompt itself.
.SH OPTIONS
.SS Interface Modes
.TP
\f[B]\-b\f[R], \f[B]\-\-responses\f[R]
Responses API calls (may be used with \f[CR]options \-cc\f[R]).
Limited support.
Set a valid model with \[lq]\f[B]\-\-model\f[R] [\f[I]name\f[R]]\[rq].
.TP
\f[B]\-c\f[R], \f[B]\-\-chat\f[R]
Chat mode in text completions (used with \f[CR]options \-wzvv\f[R]).
.TP
\f[B]\-cc\f[R]
Chat mode in chat completions (used with \f[CR]options \-wzvv\f[R]).
.TP
\f[B]\-C\f[R], \f[B]\-\-continue\f[R], \f[B]\-\-resume\f[R]
Continue from (resume) last session (cmpls/chat).
.TP
\f[B]\-d\f[R], \f[B]\-\-text\f[R]
Single\-turn session of plain text completions.
.TP
\f[B]\-dd\f[R]
Multi\-turn session of plain text completions with history support.
.TP
\f[B]\-e\f[R], \f[B]\-\-edit\f[R]
Edit first input from stdin or file (cmpls/chat).
.RS
.PP
With \f[CR]options \-eex\f[R], edit last text editor buffer from cache.
.RE
.TP
\f[B]\-E\f[R], \f[B]\-EE\f[R], \f[B]\-\-exit\f[R]
Exit on first run (even with options \-cc).
.TP
\f[B]\-g\f[R], \f[B]\-\-stream\f[R] (\f[I]defaults\f[R])
Response streaming.
.TP
\f[B]\-G\f[R], \f[B]\-\-no\-stream\f[R]
Unset response streaming.
.TP
\f[B]\-q\f[R], \f[B]\-qq\f[R], \f[B]\-\-insert\f[R]
Insert text rather than completing only.
May be set twice for multi\-turn.
.RS
.PP
Use \[lq]\f[I][insert]\f[R]\[rq] to indicate where the language model
should insert text (\[ga]instruct\[cq] and Mistral \[ga]code
models\[cq]).
.RE
.PP
\f[B]\-S\f[R] \f[B].\f[R][\f[I]PROMPT_NAME\f[R]],
\f[B]\-.\f[R][\f[I]PROMPT_NAME\f[R]]
.TP
\f[B]\-S\f[R] \f[B],\f[R][\f[I]PROMPT_NAME\f[R]], \f[B]\-,\f[R][\f[I]PROMPT_NAME\f[R]]
Load, search for, or create custom prompt.
.RS
.PP
Set \f[CR].\f[R][\f[I]PROMPT\f[R]] to load prompt silently.
.PP
Set \f[CR],\f[R][\f[I]PROMPT\f[R]] to single\-shot edit prompt.
.PP
Set \f[CR],,\f[R][\f[I]PROMPT\f[R]] to edit the prompt template file.
.PP
Set \f[CR].\f[R]\f[I]?\f[R], or \f[CR].\f[R]\f[I]list\f[R] to list all
prompt files.
.RE
.PP
\f[B]\-S\f[R], \f[B]\[en]awesome\f[R]
\f[B]/\f[R][\f[I]AWESOME_PROMPT_NAME\f[R]]
.TP
\f[B]\-S\f[R], \f[B]\[en]awesome\-zh\f[R] \f[B]%\f[R][\f[I]AWESOME_PROMPT_NAME_ZH\f[R]]
Set or search for an \f[B]awesome\-chatgpt\-prompt(\-zh)\f[R].
.RS
.PP
Set \f[B]//\f[R] or \f[B]%%\f[R] instead to refresh cache.
.RE
.PP
\f[B]\-T\f[R], \f[B]\-\-tiktoken\f[R]
.TP
\f[B]\-TT\f[R], \f[B]\-TTT\f[R]
Count input tokens with python Tiktoken (ignores special tokens).
.RS
.PP
Set twice to print tokens, thrice to available encodings.
.PP
Set the model or encoding with \f[CR]option \-m\f[R].
.PP
It heeds \f[CR]options \-ccm\f[R].
.RE
.TP
\f[B]\-w\f[R], \f[B]\-\-transcribe\f[R] [\f[I]AUD\f[R]] [\f[I]LANG\f[R]] [\f[I]PROMPT\f[R]]
Transcribe audio file speech into text.
LANG is optional.
A prompt that matches the speech language is optional.
Speech will be transcribed or translated to the target LANG.
.RS
.PP
Set twice to phrase or thrice for word\-level timestamps (\-www).
.PP
With \f[CR]options \-vv\f[R], stop voice recorder on silence auto
detection.
.RE
.TP
\f[B]\-W\f[R], \f[B]\-\-translate\f[R] [\f[I]AUD\f[R]] [\f[I]PROMPT\-EN\f[R]]
Translate audio file speech into English text.
.RS
.PP
Set twice to phrase or thrice for word\-level timestamps (\-WWW).
.RE
.TP
\f[B]\-z\f[R], \f[B]\-\-tts\f[R] [\f[I]OUTFILE\f[R]|\f[I]FORMAT\f[R]|\f[I]\-\f[R]] [\f[I]VOICE\f[R]] [\f[I]SPEED\f[R]] [\f[I]PROMPT\f[R]]
Synthesise speech from text prompt.
Takes a voice name, speed and text prompt.
.RS
.PP
Set \f[CR]option \-v\f[R] to not play response automatically.
.RE
.SS Input Modes
.TP
\f[B]\-u\f[R], \f[B]\-\-multiline\f[R]
Toggle multiline prompter, <\f[I]CTRL\-D\f[R]> flush.
.TP
\f[B]\-U\f[R], \f[B]\-\-cat\f[R]
Cat prompter, <\f[I]CTRL\-D\f[R]> flush.
.TP
\f[B]\-x\f[R], \f[B]\-xx\f[R], \f[B]\-\-editor\f[R]
Edit prompt in text editor.
.RS
.PP
Set twice to run the text editor interface a single time for the first
user input.
.PP
Set \f[CR]options \-eex\f[R] to edit last buffer from cache.
.RE
.SS Model Settings
.TP
\f[B]\-Nill\f[R]
Unset model max response tokens (chat cmpls only).
.PP
\f[B]\-NUM\f[R]
.TP
\f[B]\-M\f[R], \f[B]\-\-max\f[R] [\f[I]NUM\f[R][\f[I]\-NUM\f[R]]]
Maximum number of \f[I]response tokens\f[R].
Def=\f[I]4096\f[R].
.RS
.PP
A second number in the argument sets model capacity.
.RE
.TP
\f[B]\-N\f[R], \f[B]\-\-modmax\f[R] [\f[I]NUM\f[R]]
\f[I]Model capacity\f[R] token value.
Def=\f[I]auto\f[R], Fallback=\f[I]8000\f[R].
.TP
\f[B]\-a\f[R], \f[B]\-\-presence\-penalty\f[R] [\f[I]VAL\f[R]]
Presence penalty (cmpls/chat, \-2.0 \- 2.0).
.TP
\f[B]\-A\f[R], \f[B]\-\-frequency\-penalty\f[R] [\f[I]VAL\f[R]]
Frequency penalty (cmpls/chat, \-2.0 \- 2.0).
.PP
\f[B]\-\-effort\f[R]
[\f[I]xhigh\f[R]|\f[I]high\f[R]|\f[I]medium\f[R]|\f[I]low\f[R]|\f[I]minimal\f[R]|\f[I]none\f[R]]
(OpenAI)
.TP
\f[B]\-\-think\f[R] [\f[I]token_num\f[R]] (Anthropic / Google)
Amount of effort in reasoning models.
.TP
\f[B]\-\-format\f[R] [\f[I]mp3\f[R]|\f[I]wav\f[R]|\f[I]flac\f[R]|\f[I]opus\f[R]|\f[I]aac\f[R]|\f[I]pcm16\f[R]|\f[I]mulaw\f[R]|\f[I]ogg\f[R]]
TTS out\-file format.
Def= \f[I]mp3\f[R].
.TP
\f[B]\-j\f[R], \f[B]\-\-seed\f[R] [\f[I]NUM\f[R]]
Seed for deterministic sampling (integer).
.TP
\f[B]\-K\f[R], \f[B]\-\-top\-k\f[R] [\f[I]NUM\f[R]]
Top_k value (local\-ai, ollama, google).
.TP
\f[B]\-\-keep\-alive\f[R], \f[B]\-\-ka\f[R]=[\f[I]NUM\f[R]]
How long the model will stay loaded into memory (Ollama).
.TP
\f[B]\-m\f[R], \f[B]\-\-model\f[R] [\f[I]MODEL\f[R]]
Language \f[I]MODEL\f[R] name.
Def=\f[I]gpt\-5\f[R]/\f[I]gpt\-3.5\-turbo\-instruct\f[R].
.RS
.PP
Set \f[I]MODEL\f[R] name as \[lq]\f[I].\f[R]\[rq] to pick from the list.
.RE
.TP
\f[B]\-\-multimodal\f[R], \f[B]\-\-vision\f[R], \f[B]\-\-audio\f[R]
Model multimodal model type.
.TP
\f[B]\-n\f[R], \f[B]\-\-results\f[R] [\f[I]NUM\f[R]]
Number of results.
Def=\f[I]1\f[R].
.TP
\f[B]\-p\f[R], \f[B]\-\-top\-p\f[R] [\f[I]VAL\f[R]]
Top_p value, nucleus sampling (cmpls/chat, 0.0 \- 1.0).
.TP
\f[B]\-r\f[R], \f[B]\-\-restart\f[R] [\f[I]SEQ\f[R]]
Restart sequence string (cmpls).
.TP
\f[B]\-R\f[R], \f[B]\-\-start\f[R] [\f[I]SEQ\f[R]]
Start sequence string (cmpls).
.TP
\f[B]\-s\f[R], \f[B]\-\-stop\f[R] [\f[I]SEQ\f[R]]
Stop sequences, up to 4.
Def=\[dq]\f[I]<|endoftext|>\f[R]\[dq].
.TP
\f[B]\-S\f[R], \f[B]\-\-instruction\f[R] [\f[I]INSTRUCTION\f[R]|\f[I]FILE\f[R]]
Set an instruction text prompt.
It may be a text file.
.TP
\f[B]\-\-time\f[R], \f[B]\-\-no\-time\f[R], \f[B]\-\-date\f[R], \f[B]\-\-no\-date\f[R]
Prepend the current date and time (timestamp) to the instruction prompt.
.TP
\f[B]\-t\f[R], \f[B]\-\-temperature\f[R] [\f[I]VAL\f[R]]
Temperature value (cmpls/chat/stt), (0.0 \- 2.0, stt 0.0 \- 1.0).
Def=\f[I]0\f[R].
.TP
\f[B]\-\-no\-truncation\f[R]
Unset context truncation parameter (Responses API).
.PP
\f[B]\-\-verbosity\f[R], \f[B]\-\-verb\f[R]
[\f[I]high\f[R]|\f[I]medium\f[R]|\f[I]low\f[R]]
.TP
\f[B]\-\-no\-verbosity\f[R]
Model response verbosity level (OpenAI).
.TP
\f[B]\-\-voice\f[R] [\f[I]alloy\f[R]|\f[I]fable\f[R]|\f[I]onyx\f[R]|\f[I]nova\f[R]|\f[I]shimmer\f[R]|\f[I]ash\f[R]|\f[I]ballad\f[R]|\f[I]coral\f[R]|\f[I]sage\f[R]|\f[I]verse\f[R]|\f[I]Adelaide\-PlayAI\f[R]|\f[I]Angelo\-PlayAI\f[R]|\f[I]Arista\-PlayAI..\f[R]]
TTS voice name.
OpenAI or PlayAI (Groq) voice names.
Def=\f[I]echo\f[R], \f[I]Aaliyah\-PlayAI\f[R].
.SS Session and History Files
.TP
\f[B]\-H\f[R], \f[B]\-\-hist\f[R] [\f[CR]/\f[R]\f[I]HIST_NAME\f[R]]
Edit history file with text editor or pipe to stdout.
.RS
.PP
A history file name can be optionally set as argument.
.RE
.TP
\f[B]\-P\f[R], \f[B]\-PP\f[R], \f[B]\-\-print\f[R] [\f[CR]/\f[R]\f[I]HIST_NAME\f[R]]
Print out last history session.
.RS
.PP
Set twice to print commented out history entries, inclusive.
Heeds \f[CR]options \-bccdrR\f[R].
.PP
These are aliases to \f[B]\-HH\f[R] and \f[B]\-HHH\f[R], respectively.
.RE
.TP
\f[B]\-\-tmp\f[R]
Temporary cache location.
Defaults to subdirectory in \f[CR]$CACHEDIR\f[R], \f[CR]$TMPDIR\f[R], or
\f[CR]/tmp\f[R].
.SS Configuration File
.TP
\f[B]\-f\f[R], \f[B]\-\-no\-conf\f[R]
Ignore user configuration file.
.TP
\f[B]\-F\f[R]
Edit configuration file with text editor, if it exists.
.RS
.PP
$CHATGPTRC=\[dq]\f[I]\[ti]/.chatgpt.conf\f[R]\[dq].
.RE
.TP
\f[B]\-FF\f[R]
Dump template configuration file to stdout.
.SS Service Providers
.TP
\f[B]\-\-anthropic\f[R], \f[B]\-\-ant\f[R]
Anthropic integration (cmpls/chat).
Also see \f[B]\-\-think\f[R].
.TP
\f[B]\-\-deepseek\f[R], \f[B]\-\-deep\f[R]
DeepSeek integration (cmpls/chat).
.TP
\f[B]\-\-github\f[R], \f[B]\-\-git\f[R]
GitHub Models integration (chat).
.TP
\f[B]\-\-google\f[R], \f[B]\-goo\f[R]
Google Gemini integration (cmpls/chat).
.TP
\f[B]\-\-groq\f[R]
Groq AI integration (chat).
.TP
\f[B]\-\-localai\f[R]
LocalAI integration (cmpls/chat).
.TP
\f[B]\-\-mistral\f[R]
Mistral AI integration (chat).
.TP
\f[B]\-\-openrouter\f[R]
OpenRouter API integration (cmpls/chat).
.TP
\f[B]\-\-openai\f[R]
Reset service integrations.
.TP
\f[B]\-O\f[R], \f[B]\-\-ollama\f[R]
Ollama server integration (cmpls/chat).
.TP
\f[B]\-\-xai\f[R]
xAI Grok integration (cmpls/chat).
.SS Miscellaneous Settings
.TP
\f[B]\-\-api\-key\f[R] [\f[I]KEY\f[R]]
The API key to use.
.TP
\f[B]\-\-fold\f[R] (\f[I]defaults\f[R]), \f[B]\-\-no\-fold\f[R]
Set or unset response folding (wrap at white spaces).
.TP
\f[B]\-h\f[R], \f[B]\-\-help\f[R]
Print the help page.
.TP
\f[B]\-\-info\f[R]
Print OpenAI usage status (requires envar \f[CR]$OPENAI_ADMIN_KEY\f[R]).
.TP
\f[B]\-k\f[R], \f[B]\-\-no\-colour\f[R]
Disable colour output.
Def=\f[I]auto\f[R].
.TP
\f[B]\-l\f[R], \f[B]\-\-list\-models\f[R] [\f[I]MODEL\f[R]]
List models or print details of \f[I]MODEL\f[R].
.TP
\f[B]\-L\f[R], \f[B]\-\-log\f[R] [\f[I]FILEPATH\f[R]]
Log file.
\f[I]FILEPATH\f[R] is required.
.TP
\f[B]\-\-md\f[R], \f[B]\-\-markdown\f[R], \f[B]\-\-markdown\f[R]=[\f[I]SOFTWARE\f[R]]
Enable markdown rendering in response.
Software is optional: \f[I]bat\f[R], \f[I]pygmentize\f[R],
\f[I]glow\f[R], \f[I]mdcat\f[R], or \f[I]mdless\f[R].
.TP
\f[B]\-\-no\-md\f[R], \f[B]\-\-no\-markdown\f[R]
Disable markdown rendering.
.TP
\f[B]\-o\f[R], \f[B]\-\-clipboard\f[R]
Copy response to clipboard.
.TP
\f[B]\-v\f[R], \f[B]\-vv\f[R] 
Less interface verbosity.
.RS
.PP
Sleep after response in voice chat (\f[CR]\-vvbccw\f[R]).
.PP
With \f[CR]options \-bccwv\f[R], sleep after response.
With \f[CR]options \-bccwzvv\f[R], stop recording voice input on silence
detection and play TTS response right away.
.PP
May be set multiple times.
.RE
.TP
\f[B]\-V\f[R]
Dump raw JSON request block (debug).
.TP
\f[B]\-\-version\f[R]
Print script version.
.TP
\f[B]\-y\f[R], \f[B]\-\-tik\f[R]
Tiktoken for token count (cmpls/chat, python).
.TP
\f[B]\-Y\f[R], \f[B]\-\-no\-tik\f[R] (\f[I]defaults\f[R])
Unset tiktoken use (cmpls/chat, python).
.TP
\f[B]\-Z\f[R], \f[B]\-ZZ\f[R], \f[B]\-ZZZ\f[R], \f[B]\-\-last\f[R]
Print JSON data of the last responses.
.SH CHAT COMPLETION MODE
Set \f[CR]option \-c\f[R] to start a multi\-turn chat mode via \f[B]text
completions\f[R] with history support.
This option works with instruct models, defaults to
\f[I]gpt\-3.5\-turbo\-instruct\f[R] if none set.
.PP
Set \f[CR]options \-cc\f[R] to start the chat mode via \f[B]native chat
completions\f[R].
This mode defaults to the \f[I]gpt\-5\f[R] model, which is optimised to
follow instructions.
.PP
On \f[CR]options \-bb\f[R], the Responses API endpoint is set
preferentially.
.PP
In chat mode, some options are automatically set to un\-lobotomise the
bot.
.PP
While using other providers, mind that \f[CR]options \-c\f[R],
\f[CR]\-cc\f[R], and \f[CR]\-bb\f[R] set different endpoints!
These options must be set according to the model capabilities!
.PP
Set \f[CR]option \-C\f[R] to \f[B]resume\f[R] (continue from) last
history session, and set \f[CR]option \-E\f[R] to exit on the first
response (even in multi turn mode).
.SH TEXT COMPLETION MODE 
\f[CR]Option \-d\f[R] starts a single\-turn session in \f[B]plain text
completions\f[R], no history support.
This does not set further options automatically, such as instruction or
temperature.
.PP
To run the script in text completion in multi\-turn mode and history
support, set command line \f[CR]options \-dd\f[R].
.PP
Set text completion models such as \f[I]gpt\-3.5\-turbo\-instruct\f[R].
.SH INSERT MODE (Fill\-In\-the\-Middle)
Set \f[CR]option \-q\f[R] for \f[B]insert mode\f[R] in single\-turn and
\f[CR]option \-qq\f[R] for multi\-turn.
The flag \[lq]\f[I][insert]\f[R]\[rq] must be present in the middle of
the input prompt.
Insert mode works completing between the end of the text preceding the
flag, and ends completion with the succeeding text after the flag.
.PP
Insert mode works with \[ga]instruct\[cq] and Mistral \[ga]code\[cq]
models.
.SH RESPONSES API
Responses API is a superset of Chat Completions API.
Set command line \f[CR]option \-b\f[R] (with \f[CR]\-cc\f[R]), or set
\f[CR]options \-bb\f[R] for multi\-turn.
.PP
To activate it during multi\-turn chat, set
\f[CR]/responses [model]\f[R], where \f[I]model\f[R] is the name of a
model which works with the Responses API.
Aliased to \f[CR]/resp [model]\f[R] and \f[CR]\-b [model]\f[R].
This can be toggled.
.PP
Limited support.
.SH INSTRUCTION PROMPTS
The SYSTEM INSTRUCTION prompt may be set with \f[CR]option \-S\f[R] or
via envars \f[CR]$INSTRUCTION\f[R] and \f[CR]$INSTRUCTION_CHAT\f[R].
.PP
\f[CR]Option \-S\f[R] sets an INSTRUCTION prompt (the initial prompt)
for text cmpls, and chat cmpls.
A text file path may be supplied as the single argument.
Also see \f[B]CUSTOM / AWESOME PROMPTS\f[R] section below.
.PP
To create and reuse a custom prompt, set the prompt name as a command
line option, such as \[lq]\f[CR]\-S .[_prompt_name_]\f[R]\[rq] or
\[lq]\f[CR]\-S ,[_prompt_name_]\f[R]\[rq].
.PP
When the operator is a comma \[lq]\f[I],\f[R]\[rq], single\-shot editing
will be available after loading the prompt text.
Use double \[lq]\f[I],,\f[R]\[rq] to actually edit the template file
itself!
.PP
Note that loading a custom prompt will also change to its
respectively\-named history file.
.PP
Alternatively, set the first positional argument with the operator and
the prompt name after any command line options, such as
\[lq]\f[CR]chatgpt;sh \-cc .[_prompt_name_]\f[R]\[rq].
This loads the prompt file unless instruction was set with command line
options.
.PP
To prepend the current date and time to the instruction prompt, set
command line \f[CR]option \-\-time\f[R].
.PP
For TTS \f[I]gpt\-4o\-tts\f[R] model type instructions, set command line
option \f[CR]\-S \[dq][instruction]\[dq]\f[R] when invoking the script
with \f[CR]option \-z\f[R] only (stand\-alone TTS mode).
Alternatively, set envar \f[CR]$INSTRUCTION_SPEECH\f[R].
.PP
Note that for audio models such as \f[CR]gpt\-4o\-audio\f[R], the user
can control tone and accent of the rendered voice output with a robust
\[ga]INSTRUCTION\[cq] as usual.
.SS Prompt Engineering and Design
Minimal \f[B]INSTRUCTION\f[R] to behave like a chatbot is given with
chat \f[CR]options \-cc\f[R], unless otherwise explicitly set by the
user.
.PP
On chat mode, if no INSTRUCTION is set, minimal instruction is given,
and some options auto set, such as increasing temp and presence penalty,
in order to un\-lobotomise the bot.
.PP
Prompt engineering is an art on itself.
Study carefully how to craft the best prompts to get the most out of
text, code and chat cmpls models.
.PP
Certain prompts may return empty responses.
Maybe the model has nothing to further complete input or it expects more
text.
Try trimming spaces, appending a full stop/ellipsis, resetting
temperature, or adding more text.
.PP
Prompts ending with a space character may result in lower quality
output.
This is because the API already incorporates trailing spaces in its
dictionary of tokens.
.PP
Note that the model\[cq]s steering and capabilities require prompt
engineering to even know that it should answer the questions.
.SH MODEL AND CAPACITY
Set model with \[lq]\f[CR]\-m\f[R] [\f[I]MODEL\f[R]]\[rq], with
\f[I]MODEL\f[R] as its name, or set it as \[lq]\f[I].\f[R]\[rq] to pick
from the model list.
.PP
List models with \f[CR]option \-l\f[R] or run \f[CR]/models\f[R] in chat
mode.
.PP
Set \f[I]maximum response tokens\f[R] with \f[CR]option\f[R]
\[lq]\f[CR]\-\f[R]\f[I]NUM\f[R]\[rq] or \[lq]\f[CR]\-M\f[R]
\f[I]NUM\f[R]\[rq].
This defaults to \f[I]4096\f[R] tokens and \f[I]25000\f[R] for reasoning
models, or disabled when running on chat completions and responses
endpoints.
.PP
If a second \f[I]NUM\f[R] is given to this option, \f[I]maximum model
capacity\f[R] will also be set.
The option syntax takes the form of
\[lq]\f[CR]\-\f[R]\f[I]NUM/NUM\f[R]\[rq], and \[lq]\f[CR]\-M\f[R]
\f[I]NUM\-NUM\f[R]\[rq].
.PP
\f[I]Model capacity\f[R] (maximum model tokens) can be set more
intuitively with \f[CR]option\f[R] \[lq]\f[CR]\-N\f[R]
\f[I]NUM\f[R]\[rq], otherwise model capacity is set automatically for
known models or to \f[I]8000\f[R] tokens as fallback.
.PP
\f[CR]Option \-y\f[R] sets python tiktoken instead of the default script
hack to preview token count.
This option makes token count preview accurate and fast (we fork
tiktoken as a coprocess for fast token queries).
Useful for rebuilding history context independently from the original
model used to generate responses.
.SH SPEECH\-TO\-TEXT (Whisper)
\f[CR]Option \-w\f[R] \f[B]transcribes audio speech\f[R] from
\f[I]mp3\f[R], \f[I]mp4\f[R], \f[I]mpeg\f[R], \f[I]mpga\f[R],
\f[I]m4a\f[R], \f[I]wav\f[R], \f[I]webm\f[R], \f[I]flac\f[R] and
\f[I]ogg\f[R] files.
First positional argument must be an \f[I]AUDIO/VOICE\f[R] file.
Optionally, set a \f[I]TWO\-LETTER\f[R] input language
(\f[I]ISO\-639\-1\f[R]) as the second argument.
A PROMPT may also be set to guide the model\[cq]s style, or continue a
previous audio segment.
The text prompt should match the speech language.
.PP
Note that \f[CR]option \-w\f[R] can also be set to \f[B]translate
speech\f[R] input to any text language to the target language.
.PP
\f[CR]Option \-W\f[R] \f[B]translates speech\f[R] stream to \f[B]English
text\f[R].
A PROMPT in English may be set to guide the model as the second
positional argument.
.PP
Set these options twice to have phrasal\-level timestamps, options \-ww
and \-WW.
Set thrice for word\-level timestamps.
.PP
Combine \f[CR]options \-wW\f[R] \f[B]with\f[R] \f[CR]options \-bcc\f[R]
to start \f[B]chat with voice input\f[R] (Whisper) support.
Additionally, set \f[CR]option \-z\f[R] to enable
\f[B]text\-to\-speech\f[R] (TTS) models and voice out.
.SH TEXT\-TO\-VOICE (TTS)
\f[CR]Option \-z\f[R] synthesises voice from text (TTS models).
Set a \f[I]voice\f[R] as the first positional parameter
(\[lq]\f[I]alloy\f[R]\[rq], \[lq]\f[I]echo\f[R]\[rq],
\[lq]\f[I]fable\f[R]\[rq], \[lq]\f[I]onyx\f[R]\[rq],
\[lq]\f[I]nova\f[R]\[rq], or \[lq]\f[I]shimmer\f[R]\[rq]).
Set the second positional parameter as the \f[I]voice speed\f[R]
(\f[I]0.25\f[R] \- \f[I]4.0\f[R]), and, finally the \f[I]output file
name\f[R] or the \f[I]format\f[R], such as
\[lq]\f[I]./new_audio.mp3\f[R]\[rq] (\[lq]\f[I]mp3\f[R]\[rq],
\[lq]\f[I]wav\f[R]\[rq], \[lq]\f[I]flac\f[R]\[rq],
\[lq]\f[I]opus\f[R]\[rq], \[lq]\f[I]aac\f[R]\[rq], or
\[lq]\f[I]pcm16\f[R]\[rq]); or set \[lq]\f[I]\-\f[R]\[rq] for stdout.
.PP
Do mind that PlayAI (supported by Groq AI) has different output formats
such as \[lq]\f[I]mulaw\f[R]\[rq] and \[lq]\f[I]ogg\f[R]\[rq], as well
as different voice names such as Aaliyah\-PlayAI, Adelaide\-PlayAI,
Angelo\-PlayAI, etc.
.PP
Set \f[CR]options \-zv\f[R] to \f[I]not\f[R] play received output.
.SH MULTIMODAL AUDIO MODELS
Audio models, such as \f[I]gpt\-4o\-audio\f[R], deal with audio input
and output directly.
.PP
To activate the microphone recording function of the script, set command
line \f[CR]option \-w\f[R].
.PP
Otherwise, the audio model accepts any compatible audio file (such as
\f[B]mp3\f[R], \f[B]wav\f[R], and \f[B]opus\f[R]).
These files can be added to be loaded at the very end of the user prompt
or added with chat command \[lq]\f[CR]/audio\f[R]
\f[I]path/to/file.mp3\f[R]\[rq].
.PP
To activate the audio synthesis output mode of an audio model, make sure
to set command line \f[CR]option \-z\f[R]!
.SH TEXT / CHAT COMPLETIONS
.SS 1. Text Completion
Given a prompt, the model will return one or more predicted completions.
For example, given a partial input, the language model will try
completing it until probable \[lq]\f[CR]<|endoftext|>\f[R]\[rq], or
other stop sequences (stops may be set with
\f[CR]\-s \[dq]\[rs][stop\-seq]\[dq]\f[R]).
.PP
\f[B]Restart\f[R] and \f[B]start sequences\f[R] may be optionally set.
Restart and start sequences are not set automatically if the chat mode
of text completions is not activated with \f[CR]option \-c\f[R].
.PP
Readline is set to work with \f[B]multiline input\f[R] and pasting from
the clipboard.
Alternatively, set \f[CR]option \-u\f[R] to enable pressing
<\f[I]CTRL\-D\f[R]> to flush input!
Or set \f[CR]option \-U\f[R] to set \f[I]cat command\f[R] as input
prompter.
.PP
Bash bracketed paste is enabled, meaning multiline input may be pasted
or typed, even without setting \f[CR]options \-uU\f[R]
(\f[I]v25.2+\f[R]).
.PP
Language model \f[B]SKILLS\f[R] can be activated with specific prompts,
see \c
.UR https://platform.openai.com/examples
.UE \c
\&.
.SS 2. Interactive Conversations
.SS 2.1 Text Completions Chat
Set \f[CR]option \-c\f[R] to start chat mode of text completions.
It keeps a history file, and keeps new questions in context.
This works with a variety of models.
Set \f[CR]option \-E\f[R] to exit on response.
.SS 2.2 Native Chat Completions
Set the double \f[CR]option \-cc\f[R] to start chat completions mode.
More recent models are also the best option for many non\-chat use
cases.
.SS 2.3 Q & A Format
The defaults chat format is \[lq]\f[B]Q & A\f[R]\[rq].
The \f[B]restart sequence\f[R] \[lq]\f[I]\[rs]nQ:\ \f[R]\[rq] and the
\f[B]start text\f[R] \[lq]\f[I]\[rs]nA:\f[R]\[rq] are injected for the
chat bot to work well with text cmpls.
.PP
In multi\-turn interactions, special prefixes allow prompt manipulation:
* \f[B]\f[CB]:\f[B]\f[R]_PROMPT_ \- Prepends text to the current
\f[B]user prompt\f[R] before sending.
* \f[B]\f[CB]::\f[B]\f[R]_PROMPT_ \- Prepends text to the \f[B]system
instruction\f[R] for the current turn.
* \f[B]\f[CB]:::\f[B]\f[R] \- Re\-injects the original system
instruction into the request, useful for reinforcing instructions after
long conversations.
.PP
Entering exactly triple colons \[lq]\f[I]:::\f[R]\[rq] reinjects a
system instruction prompt into the current request.
This is useful to reinforce the instruction when the model\[cq]s context
has been truncated.
.SS 2.4 Voice input (STT), and voice output (TTS)
The \f[CR]options \-bccwz\f[R] may be combined to have voice recording
input and synthesised voice output, specially nice with chat modes.
When setting \f[CR]flag \-w\f[R] or \f[CR]flag \-z\f[R], the first
positional parameters are read as STT or TTS arguments.
When setting both \f[CR]flags \-wz\f[R], add a double hyphen to set
first STT, and then TTS arguments.
.PP
Set chat mode, plus voice\-in transcription language code and text
prompt, and the TTS voice\-out option argument:
.IP
.EX
chatgpt.sh \-bccwz  en \[aq]transcription prompt\[aq]  \-\-  nova
.EE
.SS 2.5 Vision and Multimodal Models
To send an \f[I]image\f[R] or \f[I]url\f[R] to \f[B]vision models\f[R],
either set the image with the \[lq]\f[CR]!img\f[R]\[rq] command with one
or more \f[I]filepaths\f[R] / \f[I]urls\f[R].
.IP
.EX
chatgpt.sh \-cc \-m gpt\-4\-vision\-preview \[aq]!img path/to/image.jpg\[aq]
.EE
.PP
Alternatively, set the \f[I]image paths\f[R] / \f[I]urls\f[R] at the end
of the text prompt interactively:
.IP
.EX
chatgpt.sh \-cc \-m gpt\-4\-vision\-preview

[...]
Q: In this first user prompt, what can you see?  https://i.imgur.com/wpXKyRo.jpeg
.EE
.PP
Make sure file paths containing spaces are backslash\-escaped!
.SS 2.6 Text, PDF, Doc, and URL Dumps
The user may add a \f[I]filepath\f[R] or \f[I]URL\f[R] to the end of the
prompt.
The file is then read and the text content added to the user prompt.
This is a basic text feature that works with any model.
.IP
.EX
chatgpt.sh \-cc

[...]
Q: What is this page: https://example.com

Q: Help me study this paper. \[ti]/Downloads/Prigogine\[rs] Perspective\[rs] on\[rs] Nature.pdf
.EE
.PP
In the second example, the \f[I]PDF\f[R] will be dumped as text.
.PP
For PDF text dump support, \f[CR]poppler/abiword\f[R] is required.
For \f[I]doc\f[R] and \f[I]odt\f[R] files, \f[CR]LibreOffice\f[R] is
required.
See the \f[B]Optional Packages\f[R] section.
.PP
Also note that \f[I]file paths\f[R] containing white spaces must be
\f[B]backslash\-escaped\f[R], or the \f[I]file path\f[R] must be
preceded by a pipe \[ga]|\[cq] character.
.PP
Multiple images and audio files may be added to the request in this way!
.SH COMMAND LIST
While in chat mode, the following commands can be invoked to change
parameters and manage sessions.
.IP \[bu] 2
Commands can start with either \[lq]\f[CR]!\f[R]\[rq] or
\[lq]\f[CR]/\f[R]\[rq] and are \f[I]usually equivalent\f[R].
.IP \[bu] 2
Commands with \f[B]colon\f[R] (\f[CR]:\f[R]) add their output to the
current prompt buffer.
.IP \[bu] 2
Commands with \f[B]double dagger\f[R] \f[CR]‡\f[R] execute as as suffix
command, see examples below.
.SS Command Tables
.PP
.TS
tab(@);
l l l.
T{
Misc
T}@T{
Commands
T}@T{
T}
_
T{
\f[CR]\-S\f[R]
T}@T{
[\f[I]PROMPT\f[R]]
T}@T{
Set (overwrite) or unset the system instruction.
T}
T{
\f[CR]\-S:\f[R]
T}@T{
\f[CR]:\f[R] [\f[I]PROMPT\f[R]]
T}@T{
Prepend to current \f[I]user\f[R] prompt.
T}
T{
\f[CR]\-S::\f[R]
T}@T{
\f[CR]::\f[R] [\f[I]PROMPT\f[R]]
T}@T{
Prepend to system instruction.
T}
T{
\f[CR]\-S:::\f[R]
T}@T{
\f[CR]:::\f[R]
T}@T{
Restore the previously set system instruction.
T}
T{
\f[CR]\-S.\f[R]
T}@T{
\f[CR]\-.\f[R] [\f[I]NAME\f[R]]
T}@T{
Load and edit custom instruction prompt.
T}
T{
\f[CR]\-S/\f[R]
T}@T{
\f[CR]!awesome\f[R] [\f[I]NAME\f[R]]
T}@T{
Load and edit awesome prompt (english).
T}
T{
\f[CR]\-S%\f[R]
T}@T{
\f[CR]!awesome\-zh\f[R] [\f[I]NAME\f[R]]
T}@T{
Load and edit awesome prompt (chinese).
T}
T{
\f[CR]\-Z\f[R]
T}@T{
\f[CR]!last\f[R]
T}@T{
Print last raw JSON or the processed text response.
T}
T{
\f[CR]!#\f[R]
T}@T{
\f[CR]!save\f[R] [\f[I]PROMPT\f[R]]
T}@T{
Save current prompt to shell history (readline).
\f[I]‡\f[R]
T}
T{
\f[CR]!\f[R]
T}@T{
\f[CR]!r\f[R], \f[CR]!regen\f[R]
T}@T{
Regenerate last response.
T}
T{
\f[CR]!!\f[R]
T}@T{
\f[CR]!rr\f[R]
T}@T{
Regenerate response, edit prompt first.
T}
T{
\f[CR]!g:\f[R]
T}@T{
\f[CR]!!g:\f[R] [\f[I]PROMPT\f[R]]
T}@T{
Ground user prompt with web search results.
\f[I]‡\f[R]
T}
T{
\f[CR]!i\f[R]
T}@T{
\f[CR]!info\f[R] [\f[I]REGEX\f[R]]
T}@T{
Information on model and session settings.
T}
T{
\f[CR]!!i\f[R]
T}@T{
\f[CR]!!info\f[R]
T}@T{
Monthly usage stats (OpenAI).
T}
T{
\f[CR]!j\f[R]
T}@T{
\f[CR]!jump\f[R]
T}@T{
Jump to request, append start seq primer (text cmpls).
T}
T{
\f[CR]!!j\f[R]
T}@T{
\f[CR]!!jump\f[R]
T}@T{
Jump to request, no response priming.
T}
T{
\f[CR]!cat\f[R]
T}@T{
\-
T}@T{
Cat prompter as one\-shot, <\f[I]CTRL\-D\f[R]> flush.
T}
T{
\f[CR]!cat\f[R]
T}@T{
\f[CR]!cat:\f[R] [\f[I]TXT\f[R]|\f[I]URL\f[R]|\f[I]PDF\f[R]]
T}@T{
Cat \f[I]text\f[R], \f[I]PDF\f[R] file, or dump \f[I]URL\f[R].
T}
T{
\f[CR]!clot\f[R]
T}@T{
\f[CR]!!clot\f[R]
T}@T{
Flood the TTY with patterns, as visual separator.
T}
T{
\f[CR]!dialog\f[R]
T}@T{
\-
T}@T{
Toggle the \[lq]dialog\[rq] interface.
T}
T{
\f[CR]!img\f[R]
T}@T{
\f[CR]!media\f[R] [\f[I]FILE\f[R]|\f[I]URL\f[R]]
T}@T{
Add image, media, or URL to prompt.
T}
T{
\f[CR]!md\f[R]
T}@T{
\f[CR]!markdown\f[R] [\f[I]SOFTW\f[R]]
T}@T{
Toggle markdown rendering in response.
T}
T{
\f[CR]!!md\f[R]
T}@T{
\f[CR]!!markdown\f[R] [\f[I]SOFTW\f[R]]
T}@T{
Render last response in markdown.
T}
T{
\f[CR]!rep\f[R]
T}@T{
\f[CR]!replay\f[R]
T}@T{
Replay last TTS audio response.
T}
T{
\f[CR]!res\f[R]
T}@T{
\f[CR]!resubmit\f[R]
T}@T{
Resubmit last STT recorded audio in cache.
T}
T{
\f[CR]!p\f[R]
T}@T{
\f[CR]!pick\f[R] [\f[I]PROPMT\f[R]]
T}@T{
File picker, appends filepath to user prompt.
\f[I]‡\f[R]
T}
T{
\f[CR]!pdf\f[R]
T}@T{
\f[CR]!pdf:\f[R] [\f[I]FILE\f[R]]
T}@T{
Convert PDF and dump text.
T}
T{
\f[CR]!photo\f[R]
T}@T{
\f[CR]!!photo\f[R] [\f[I]INDEX\f[R]]
T}@T{
Take a photo, optionally set camera index (Termux).
\f[I]‡\f[R]
T}
T{
\f[CR]!sh\f[R]
T}@T{
\f[CR]!shell\f[R] [\f[I]CMD\f[R]]
T}@T{
Run shell \f[I]command\f[R] and edit stdout (make request).
\f[I]‡\f[R]
T}
T{
\f[CR]!sh:\f[R]
T}@T{
\f[CR]!shell:\f[R] [\f[I]CMD\f[R]]
T}@T{
Same as \f[CR]!sh\f[R] and insert stdout into current prompt.
T}
T{
\f[CR]!!sh\f[R]
T}@T{
\f[CR]!!shell\f[R] [\f[I]CMD\f[R]]
T}@T{
Run interactive shell \f[I]command\f[R] and return.
T}
T{
\f[CR]!time\f[R]
T}@T{
\f[CR]!date\f[R]
T}@T{
Add timestamp to the start of user prompt.
‡
T}
T{
\f[CR]!url\f[R]
T}@T{
\f[CR]!url:\f[R] [\f[I]URL\f[R]]
T}@T{
Dump URL text or YouTube transcript text.
T}
.TE
.PP
.TS
tab(@);
l l l.
T{
Script
T}@T{
Settings and UX
T}@T{
T}
_
T{
\f[CR]!fold\f[R]
T}@T{
\f[CR]!wrap\f[R]
T}@T{
Toggle response wrapping.
T}
T{
\f[CR]\-F\f[R]
T}@T{
\f[CR]!conf\f[R]
T}@T{
Runtime configuration form TUI.
T}
T{
\f[CR]\-g\f[R]
T}@T{
\f[CR]!stream\f[R]
T}@T{
Toggle response streaming.
T}
T{
\f[CR]\-h\f[R]
T}@T{
\f[CR]!help\f[R] [\f[I]REGEX\f[R]]
T}@T{
Print help or grep help for regex.
T}
T{
\f[CR]\-l\f[R]
T}@T{
\f[CR]!models\f[R] [\f[I]NAME\f[R]]
T}@T{
List language models or show model details.
T}
T{
\f[CR]\-o\f[R]
T}@T{
\f[CR]!clip\f[R]
T}@T{
Copy responses to clipboard.
T}
T{
\f[CR]\-u\f[R]
T}@T{
\f[CR]!multi\f[R]
T}@T{
Toggle multiline prompter.
<\f[I]CTRL\-D\f[R]> flush.
T}
T{
\f[CR]\-uu\f[R]
T}@T{
\f[CR]!!multi\f[R]
T}@T{
Multiline, one\-shot.
<\f[I]CTRL\-D\f[R]> flush.
T}
T{
\f[CR]\-U\f[R]
T}@T{
\f[CR]\-UU\f[R]
T}@T{
Toggle cat prompter or set one\-shot.
<\f[I]CTRL\-D\f[R]> flush.
T}
T{
\f[CR]\-V\f[R]
T}@T{
\f[CR]!debug\f[R]
T}@T{
Dump raw request block and confirm.
T}
T{
\f[CR]\-v\f[R]
T}@T{
\-
T}@T{
Toggle interface verbose modes.
T}
T{
\f[CR]\-x\f[R]
T}@T{
\f[CR]!ed\f[R]
T}@T{
Toggle text editor interface.
T}
T{
\f[CR]\-xx\f[R]
T}@T{
\f[CR]!!ed\f[R]
T}@T{
Single\-shot text editor.
T}
T{
\f[CR]\-y\f[R]
T}@T{
\f[CR]!tik\f[R]
T}@T{
Toggle python tiktoken use.
T}
T{
\f[CR]!q\f[R]
T}@T{
\f[CR]!quit\f[R]
T}@T{
Exit.
Bye.
T}
.TE
.PP
.TS
tab(@);
l l l.
T{
Model
T}@T{
Settings
T}@T{
T}
_
T{
\f[CR]!Nill\f[R]
T}@T{
\f[CR]\-Nill\f[R]
T}@T{
Unset max response tokens (chat cmpls).
T}
T{
\f[CR]!NUM\f[R]
T}@T{
\f[CR]\-M\f[R] [\f[I]NUM\f[R]]
T}@T{
Maximum response tokens.
T}
T{
\f[CR]!!NUM\f[R]
T}@T{
\f[CR]\-N\f[R] [\f[I]NUM\f[R]]
T}@T{
Model token capacity.
T}
T{
\f[CR]\-a\f[R]
T}@T{
\f[CR]!pre\f[R] [\f[I]VAL\f[R]]
T}@T{
Presence penalty.
T}
T{
\f[CR]\-A\f[R]
T}@T{
\f[CR]!freq\f[R] [\f[I]VAL\f[R]]
T}@T{
Frequency penalty.
T}
T{
\f[CR]\-b\f[R]
T}@T{
\f[CR]!responses\f[R] [\f[I]MOD\f[R]]
T}@T{
Responses API request (experimental).
T}
T{
\f[CR]\-j\f[R]
T}@T{
\f[CR]!seed\f[R] [\f[I]NUM\f[R]]
T}@T{
Seed number (integer).
T}
T{
\f[CR]\-K\f[R]
T}@T{
\f[CR]!topk\f[R] [\f[I]NUM\f[R]]
T}@T{
Top_k.
T}
T{
\f[CR]\-m\f[R]
T}@T{
\f[CR]!mod\f[R] [\f[I]MOD\f[R]]
T}@T{
Model by name, empty to pick from list.
T}
T{
\f[CR]\-n\f[R]
T}@T{
\f[CR]!results\f[R] [\f[I]NUM\f[R]]
T}@T{
Number of results.
T}
T{
\f[CR]\-p\f[R]
T}@T{
\f[CR]!topp\f[R] [\f[I]VAL\f[R]]
T}@T{
Top_p.
T}
T{
\f[CR]\-r\f[R]
T}@T{
\f[CR]!restart\f[R] [\f[I]SEQ\f[R]]
T}@T{
Restart sequence.
T}
T{
\f[CR]\-R\f[R]
T}@T{
\f[CR]!start\f[R] [\f[I]SEQ\f[R]]
T}@T{
Start sequence.
T}
T{
\f[CR]\-s\f[R]
T}@T{
\f[CR]!stop\f[R] [\f[I]SEQ\f[R]]
T}@T{
One stop sequence.
T}
T{
\f[CR]\-t\f[R]
T}@T{
\f[CR]!temp\f[R] [\f[I]VAL\f[R]]
T}@T{
Temperature.
T}
T{
\f[CR]\-w\f[R]
T}@T{
\f[CR]!rec\f[R] [\f[I]ARGS\f[R]]
T}@T{
Toggle voice\-in STT.
Optionally, set arguments.
T}
T{
\f[CR]\-z\f[R]
T}@T{
\f[CR]!tts\f[R] [\f[I]ARGS\f[R]]
T}@T{
Toggle TTS chat mode (speech out).
T}
T{
\f[CR]!blk\f[R]
T}@T{
\f[CR]!block\f[R] [\f[I]ARGS\f[R]]
T}@T{
Set and add custom options to JSON request.
T}
T{
\f[CR]!effort\f[R]
T}@T{
\- [\f[I]MODE\f[R]]
T}@T{
Effort: xhigh, high, medium, low, minimal, or none (OpenAI).
T}
T{
\f[CR]!think\f[R]
T}@T{
\- [\f[I]NUM\f[R]]
T}@T{
Budget: token value (Anthropic).
T}
T{
\f[CR]!ka\f[R]
T}@T{
\f[CR]!keep\-alive\f[R] [\f[I]NUM\f[R]]
T}@T{
Set duration of model load in memory (Ollama).
T}
T{
\f[CR]!verb\f[R]
T}@T{
\f[CR]!verbosity\f[R] [\f[I]MODE\f[R]]
T}@T{
Model verbosity level (high, medium, or low).
T}
T{
\f[CR]!vision\f[R]
T}@T{
\f[CR]!audio\f[R], \f[CR]!multimodal\f[R]
T}@T{
Toggle multimodality type.
T}
.TE
.PP
.TS
tab(@);
l l l.
T{
Session
T}@T{
Management
T}@T{
T}
_
T{
\f[CR]\-C\f[R]
T}@T{
\-
T}@T{
Continue current history session (see \f[CR]!break\f[R]).
T}
T{
\f[CR]\-H\f[R]
T}@T{
\f[CR]!hist\f[R] [\f[I]NUM\f[R]]
T}@T{
Edit history in editor or print the last \f[I]n\f[R] history entries.
T}
T{
\f[CR]\-P\f[R]
T}@T{
\f[CR]\-HH\f[R], \f[CR]!print\f[R]
T}@T{
Print session history.
T}
T{
\f[CR]\-L\f[R]
T}@T{
\f[CR]!log\f[R] [\f[I]FILEPATH\f[R]]
T}@T{
Save to log file.
T}
T{
\f[CR]!c\f[R]
T}@T{
\f[CR]!copy\f[R] [\f[I]SRC_HIST\f[R]] [\f[I]DEST_HIST\f[R]]
T}@T{
Copy session from source to destination.
T}
T{
\f[CR]!f\f[R]
T}@T{
\f[CR]!fork\f[R] [\f[I]DEST_HIST\f[R]]
T}@T{
Fork current session and continue from destination.
T}
T{
\f[CR]!k\f[R]
T}@T{
\f[CR]!kill\f[R] [\f[I]NUM\f[R]]
T}@T{
Comment out \f[I]n\f[R] last entries in history file.
T}
T{
\f[CR]!!k\f[R]
T}@T{
\f[CR]!!kill\f[R] [[\f[I]0\f[R]]\f[I]NUM\f[R]]
T}@T{
Dry\-run of command \f[CR]!kill\f[R].
T}
T{
\f[CR]!s\f[R]
T}@T{
\f[CR]!session\f[R] [\f[I]HIST_NAME\f[R]]
T}@T{
Change to, search for, or create history file.
T}
T{
\f[CR]!!s\f[R]
T}@T{
\f[CR]!!session\f[R] [\f[I]HIST_NAME\f[R]]
T}@T{
Same as \f[CR]!session\f[R], break session.
T}
T{
\f[CR]!u\f[R]
T}@T{
\f[CR]!unkill\f[R] [\f[I]NUM\f[R]]
T}@T{
Uncomment \f[I]n\f[R] last entries in history file.
T}
T{
\f[CR]!!u\f[R]
T}@T{
\f[CR]!!unkill\f[R] [[\f[I]0\f[R]]\f[I]NUM\f[R]]
T}@T{
Dry\-run of command \f[CR]!unkill\f[R].
T}
T{
\f[CR]!br\f[R]
T}@T{
\f[CR]!break\f[R], \f[CR]!new\f[R]
T}@T{
Start new session (session break).
T}
T{
\f[CR]!ls\f[R]
T}@T{
\f[CR]!list\f[R] [\f[I]GLOB\f[R]|\f[I].\f[R]|\f[I]pr\f[R]|\f[I]awe\f[R]]
T}@T{
List history files with \[lq]\f[I]glob\f[R]\[rq] in \f[I]name\f[R];
Files: \[lq]\f[I].\f[R]\[rq]; Prompts: \[lq]\f[I]pr\f[R]\[rq]; Awesome:
\[lq]\f[I]awe\f[R]\[rq].
T}
T{
\f[CR]!grep\f[R]
T}@T{
\f[CR]!sub\f[R] [\f[I]REGEX\f[R]]
T}@T{
Grep sessions and copy session to hist tail.
T}
T{
\f[CR]!tmp\f[R]
T}@T{
\f[CR]!!tmp\f[R]
T}@T{
Fork session to a temporary cache.
T}
.TE
.PP
\f[I]:\f[R] Commands with \f[B]colons\f[R] add their output to the
current prompt buffer.
.PP
\f[I]‡\f[R] \f[B]Double daggers\f[R] indicates suffix\-commands, invoked
at the end of the user prompt and preceded by space.
.PP
   *   *   *   *   *
.PP
Examples
.PP
\ \ \[lq]\f[CR]/temp\f[R] \f[I]0.7\f[R]\[rq],
\[lq]\f[CR]!mod\f[R]\f[I]gpt\-5\f[R]\[rq], \[lq]\f[CR]\-p\f[R]
\f[I]0.2\f[R]\[rq]
.PP
\ \ \[lq]\f[CR]/session\f[R] \f[I]HIST_NAME\f[R]\[rq],
\[lq][\f[I]PROMPT\f[R]] \f[CR]/pick\f[R]\[rq]
.PP
\ \ \[lq][\f[I]PROMPT\f[R]] \f[CR]/sh\f[R]\[rq], \[lq]\f[I]Translate
this to French\f[R] \f[CR]/sh\f[R]\[rq]
.PP
   *   *   *   *   *
.PP
Some options can be disabled and excluded from the request by setting a
\[lq]\f[I]\-1\f[R]\[rq] as argument (bypass with
\[lq]\f[I]\-1.0\f[R]\[rq])
.PP
\ \ \[lq]\f[CR]!presence\f[R] \f[I]\-1\f[R]\[rq], \[lq]\f[CR]\-a\f[R]
\f[I]\-1\f[R]\[rq], \[lq]\f[CR]\-t\f[R]\f[I]\-1\f[R]\[rq]
.PP
   *   *   *   *   *
.SS Response Regeneration
To \f[B]regenerate response\f[R], type in the command
\[lq]\f[CR]!regen\f[R]\[rq] or a single exclamation mark or forward
slash in the new empty prompt.
In order to edit the prompt before the request, try
\[lq]\f[CR]!!\f[R]\[rq] (or \[lq]\f[CR]//\f[R]\[rq]).
.SS Shell and File Integration
The \[lq]\f[CR]/pick\f[R]\[rq] command opens a file picker (usually a
command\-line file manager).
The selected file path will be appended to the current prompt in editing
mode.
.PP
The \[lq]\f[CR]/sh\f[R]\[rq] and \[lq]\f[CR]/pick\f[R]\[rq] commands may
be run when typed at the end of the current prompt, such as
\[lq][\f[I]PROMPT\f[R]] \f[CR]/sh\f[R]\[rq], which opens a new shell
instance to execute commands interactively.
Shell command or file dumps are appended to the current prompt.
.PP
Any command prefixed with a single exclamation mark (\f[CR]!CMD\f[R])
that does not match a built\-in command is executed by the shell.
This is a shortcut for \f[CR]!sh CMD\f[R], and its standard output is
appended to the current prompt.
.PP
To execute a shell command without appending its output, use the double
exclamation mark form explicitly (\f[CR]!!sh CMD\f[R]).
This shell execution facility is exclusive to the \f[CR]!\f[R] operator.
.SS API Parameter Injection
Envar \f[B]$BLOCK_USR\f[R] can be set to raw model options in JSON
syntax, according to each API, to be injected in the request block.
Alternatively, run command \[lq]\f[CR]!block\f[R] [\f[I]ARGS\f[R]]\[rq]
during chat mode.
.SH Session Management
A history file can hold a single session or multiple sessions.
When it holds a single session, the name of the history file and the
session are the same.
However, in case the user breaks a session, the last one (the tail
session) of that history file is always loaded when the resume
\f[CR]option \-C\f[R] is set.
.PP
The script uses a \f[I]TSV file\f[R] to record entries, which is kept at
the script cache directory
(\[lq]\f[CR]\[ti]/.cache/chatgptsh/\f[R]\[rq]).
The \f[B]tail session\f[R] of the history file can always be read and
resumed.
.PP
Run command \[lq]\f[CR]/list [glob]\f[R]\[rq] with optional
\[lq]\f[I]glob\f[R]\[rq] to list session / history
\[lq]\f[I]tsv\f[R]\[rq] files.
When glob is \[lq]\f[I].\f[R]\[rq] list all files in the cache
directory; when \[lq]\f[I]pr\f[R]\[rq] list all instruction prompt
files; and when \[lq]\f[I]awe\f[R]\[rq] list all awesome prompts.
.SS Changing Session
A new history file can be created or changed to with command
\[lq]\f[CR]/session\f[R] [\f[I]HIST_NAME\f[R]]\[rq], in which
\f[I]HIST_NAME\f[R] is the file name or path of a history file.
.PP
On invocation, when the first positional argument to the script follows
the syntax \[lq]\f[CR]/\f[R][\f[I]HIST_NAME\f[R]]\[rq], the command
\[lq]\f[CR]/session\f[R]\[rq] is assumed (with
\f[CR]options \-bccCdPP\f[R]).
.SS Resuming and Copying Sessions
To continue from an old session type in a dot \[lq]\f[CR].\f[R]\[rq] or
\[lq]\f[CR]/.\f[R]\[rq] as the first positional argument from the
command line on invocation.
.PP
The above command is a shortcut of \[lq]\f[CR]/copy\f[R]
\f[I]current\f[R] \f[I]current\f[R]\[rq].
In fact, there are multiple commands to copy and resume from an older
session (the dot means \f[I]current session\f[R]):
\[lq]\f[CR]/copy . .\f[R]\[rq], \[lq]\f[CR]/fork.\f[R]\[rq],
\[lq]\f[CR]/sub\f[R]\[rq], and \[lq]\f[CR]/grep\f[R]
[\f[I]REGEX\f[R]]\[rq].
.PP
From the command line on invocation, simply type \[lq]\f[CR].\f[R]\[rq]
as the first positional argument.
.PP
It is possible to copy sessions of a history file to another file when a
second argument is given to the \[lq]\f[CR]/copy\f[R]\[rq] command.
.PP
Mind that forking a session will change to the destination history file
and resume from it as opposed to just copying it.
.SS History File Editing
To edit chat context at run time, the history file may be modified with
the \[lq]\f[CR]/hist\f[R]\[rq] command (also good for context
injection).
.PP
Delete history entries or comment them out with \[lq]#\[rq].
.SH CUSTOM / AWESOME PROMPTS
When the argument to \f[CR]option \-S\f[R] starts with a full stop, such
as \[lq]\f[CR]\-S\f[R] \f[CR].\f[R]\f[I]my_prompt\f[R]\[rq], load,
search for, or create \f[I]my_prompt\f[R] prompt file.
If two full stops are prepended to the prompt name, load it silently.
If a comma is used instead, such as \[lq]\f[CR]\-S\f[R]
\f[CR],\f[R]\f[I]my_prompt\f[R]\[rq], edit the prompt file, and then
load it.
.PP
When the argument to \f[CR]option \-S\f[R] starts with a backslash or a
percent sign, such as \[lq]\f[CR]\-S\f[R]
\f[CR]/\f[R]\f[I]linux_terminal\f[R]\[rq], search for an
\f[B]awesome\-chatgpt\-prompt(\-zh)\f[R] (by Fatih KA and PlexPt).
Set \[lq]\f[CR]//\f[R]\[rq] or \[lq]\f[CR]%%\f[R]\[rq] to refresh local
cache.
Use with \f[I]davinci\f[R] and \f[I]gpt\-3.5+\f[R] models.
.PP
These options also set corresponding history files automatically.
.PP
Please note and make sure to backup your important custom prompts!
They are located at \[lq]\f[CR]\[ti]/.cache/chatgptsh/\f[R]\[rq] with
the extension \[lq]\f[I].pr\f[R]\[rq].
.SH STT / VOICE\-IN / WHISPER
.SS Transcriptions
Transcribes audio file or voice record into the set language.
Set a \f[I]two\-letter\f[R] \f[I]ISO\-639\-1\f[R] language code
(\f[I]en\f[R], \f[I]es\f[R], \f[I]ja\f[R], or \f[I]zh\f[R]) as the
positional argument following the input audio file.
A prompt may also be set as last positional parameter to help guide the
model.
This prompt should match the audio language.
.PP
If the last positional argument is \[lq].\[rq] or \[lq]last\[rq]
exactly, it will resubmit the last recorded audio input file from cache.
.PP
Note that if the audio language is different from the set language code,
output will be on the language code (translation).
.SS Translations
Translates audio into \f[B]English\f[R].
An optional text to guide the model\[cq]s style or continue a previous
audio segment is optional as last positional argument.
This prompt should be in English.
.PP
Setting \f[B]temperature\f[R] has an effect, the higher the more random.
.SH PROVIDER INTEGRATIONS
For LocalAI integration, run the script with
\f[CR]option \-\-localai\f[R], or set environment
\f[B]$OPENAI_BASE_URL\f[R] with the server Base URL.
.PP
For Mistral AI set environment variable \f[B]$MISTRAL_API_KEY\f[R], and
run the script with \f[CR]option \-\-mistral\f[R] or set
\f[B]$OPENAI_BASE_URL\f[R] to \[lq]https://api.mistral.ai/\[rq].
Prefer setting command line \f[CR]option \-\-mistral\f[R] for complete
integration.
.PP
For Ollama, set \f[CR]option \-O\f[R] (\f[CR]\-\-ollama\f[R]), and set
\f[B]$OLLAMA_BASE_URL\f[R] if the server URL is different from the
defaults.
.PP
Note that model management (downloading and setting up) must follow the
Ollama project guidelines and own methods.
.PP
Likewise, for other supported service providers, use command line
options, or for unknown providers, use environmental variables for
configuiration.
.PP
Many service providers can be wrapped by this script.
See our repository documentation with the example on how to set up
\f[B]Novita AI API\f[R] integration.
.PP
Some service providers and models may also work with pure text
completions, which is turned on with command\-line \f[CR]option \-c\f[R]
instead.
.PP
Prompt caching is manually enabled for Anthropic API and models,  see
\f[B]BUGS section\f[R].
.SH ENVIRONMENT
\f[B]BLOCK_USR\f[R]
.TP
\f[B]BLOCK_USR_TTS\f[R]
Extra options for the request JSON block
(e.g.\ \[lq]\f[I]\[dq]seed\[dq]: 33, \[dq]dimensions\[dq]:
1024\f[R]\[rq]).
.TP
\f[B]CACHEDIR\f[R]
Script cache directory base.
.TP
\f[B]CHATGPTRC\f[R]
Path to the user \f[I]configuration file\f[R].
.RS
.PP
Defaults=\[dq]\f[I]\[ti]/.chatgpt.conf\f[R]\[dq]
.RE
.TP
\f[B]FILECHAT\f[R]
Path to a history / session TSV file (script\-formatted).
.TP
\f[B]INSTRUCTION\f[R]
Initial initial instruction message.
.TP
\f[B]INSTRUCTION_CHAT\f[R]
Initial initial instruction or system message in chat mode.
.TP
\f[B]INSTRUCTION_SPEECH\f[R]
TTS transcription model instruction (gpt\-4o\-tts models).
.PP
\f[B]LC_ALL\f[R]
.TP
\f[B]LANG\f[R]
Default instruction language in chat mode.
.PP
\f[B]MOD_CHAT\f[R], \f[B]MOD_AUDIO\f[R], \f[B]MOD_SPEECH\f[R],
.PP
\f[B]MOD_LOCALAI\f[R], \f[B]MOD_OLLAMA\f[R], \f[B]MOD_MISTRAL\f[R],
.PP
\f[B]MOD_AUDIO_MISTRAL\f[R], \f[B]MOD_GOOGLE\f[R], \f[B]MOD_GROQ\f[R],
.PP
\f[B]MOD_AUDIO_GROQ\f[R], \f[B]MOD_SPEECH_GROQ\f[R],
\f[B]MOD_ANTHROPIC\f[R],
.TP
\f[B]MOD_GITHUB\f[R], \f[B]MOD_OPENROUTER\f[R], \f[B]MOD_XAI\f[R], \f[B]MOD_DEEPSEEK\f[R]
Set default model for each endpoint / provider.
.PP
\f[B]OPENAI_BASE_URL\f[R]
.TP
\f[B]OPENAI_URL_PATH\f[R]
Main Base URL setting.
Alternatively, provide a \f[I]URL_PATH\f[R] parameter with the full url
path to disable endpoint auto selection.
.TP
\f[B]PROVIDER_BASE_URL\f[R]
Base URLs for each service provider: \f[I]LOCALAI\f[R],
\f[I]OLLAMA\f[R], \f[I]MISTRAL\f[R], \f[I]GOOGLE\f[R],
\f[I]ANTHROPIC\f[R], \f[I]GROQ\f[R], \f[I]GITHUB\f[R],
\f[I]OPENROUTER\f[R], \f[I]XAI\f[R], and \f[I]DEEPSEEK\f[R].
.PP
\f[B]OPENAI_API_KEY\f[R]
.PP
\f[B]PROVIDER_API_KEY\f[R]
.TP
\f[B]GITHUB_TOKEN\f[R]
Keys for OpenAI, Gemini, Mistral, Groq, Anthropic, GitHub Models,
OpenRouter, xAI, and DeepSeek APIs.
.TP
\f[B]OUTDIR\f[R]
Output directory for received audio and files.
.PP
\f[B]RESTART\f[R]
.TP
\f[B]START\f[R]
Restart and start sequences.
May be set to \f[I]null\f[R].
.RS
.PP
Restart=\[lq]\f[I]\[rs]nQ:\ \f[R]\[rq]
Start=\[dq]\f[I]\[rs]nA:\f[R]\[dq] (chat mode)
.RE
.PP
\f[B]VISUAL\f[R]
.TP
\f[B]EDITOR\f[R]
Text editor for external prompt editing.
.RS
.PP
Defaults=\[dq]\f[I]vim\f[R]\[dq]
.RE
.TP
\f[B]CLIP_CMD\f[R]
Clipboard set command, e.g.\ \[lq]\f[I]xsel\f[R] \f[I]\-b\f[R]\[rq],
\[lq]\f[I]pbcopy\f[R]\[rq].
.TP
\f[B]PLAY_CMD\f[R]
Audio player command, e.g.\ \[lq]\f[I]mpv \[en]no\-video
\[en]vo=null\f[R]\[rq].
.TP
\f[B]REC_CMD\f[R]
Audio recorder command, e.g.\ \[lq]\f[I]sox \-d\f[R]\[rq].
.SH Web Search
.SS Simple Search Dump
To ground a user prompt with search results, run chat command
\[lq]\f[CR]/g [prompt]\f[R]\[rq].
.PP
Default search provider is Google.
To select a different search provider, run
\[lq]\f[CR]//g [prompt]\f[R]\[rq] and choose amongst \f[I]Google\f[R],
\f[I]DuckDuckGo\f[R], or \f[I]Brave\f[R].
.PP
Running \[lq]\f[CR]//g [prompt]\f[R]\[rq] will always use the in\-house
solution instead of any service provider specific web search tool.
.PP
A cli\-browser is required, such as \f[B]w3m\f[R], \f[B]elinks,
\f[R]links\f[B], or \f[R]lynx**.
.SS OpenAI Web Search
Use the in\-house solution above, or select models with \[lq]search\[rq]
in the name, such as \[lq]gpt\-4o\-search\-preview\[rq].
.SS xAI Live Search
.IP
.EX
export BLOCK_USR=\[aq]\[dq]search_parameters\[dq]: {
  \[dq]mode\[dq]: \[dq]auto\[dq],
  \[dq]max_search_results\[dq]: 10
}\[aq]

chatgpt.sh \-\-xai \-cc \-m grok\-3\-latest 
.EE
.PP
Check more search parameters at the xAI API documentation: \c
.UR https://docs.x.ai/docs/guides/live-search
.UE \c
\&.
.SS Anthropic Web Search
.IP
.EX
export BLOCK_USR=\[aq]\[dq]tools\[dq]: [{
  \[dq]type\[dq]: \[dq]web_search_20250305\[dq],
  \[dq]name\[dq]: \[dq]web_search\[dq],
  \[dq]max_uses\[dq]: 5
}]\[aq]

chatgpt.sh \-\-ant \-cc \-m claude\-opus\-4\-0
.EE
.PP
Check more web search parameters at Anthropic API docs: \c
.UR https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking
.UE \c
\&.
.SS Google Search
.IP
.EX
export BLOCK_CMD=\[aq]\[dq]tools\[dq]: [ { \[dq]google_search\[dq]: {} } ]\[aq]

chatgpt.sh \-\-goo \-cc \-m gemini\-2.5\-flash\-preview\-05\-20
.EE
.PP
Check more web search parameters at Google AI API docs: \c
.UR https://ai.google.dev/gemini-api/docs/grounding?lang=rest
.UE \c
\&.
.SH COLOR THEMES
The colour scheme may be customised.
A few themes are available in the template configuration file.
.PP
A small colour library is available for the user conf file to
personalise the theme colours.
.PP
The colour palette is composed of \f[I]$Red\f[R], \f[I]$Green\f[R],
\f[I]$Yellow\f[R], \f[I]$Blue\f[R], \f[I]$Purple\f[R], \f[I]$Cyan\f[R],
\f[I]$White\f[R], \f[I]$Inv\f[R] (invert), and \f[I]$Nc\f[R] (reset)
variables.
.PP
Bold variations are defined as \f[I]$BRed\f[R], \f[I]$BGreen\f[R], etc,
and background colours can be set with \f[I]$On_Yellow\f[R],
\f[I]$On_Blue\f[R], etc.
.PP
Alternatively, raw escaped color sequences, such as
\f[I]\[rs]u001b[0;35m\f[R], and \f[I]\[rs]u001b[1;36m\f[R] may be set.
.PP
Theme colours are named variables from \f[CR]Colour1\f[R] to about
\f[CR]Colour11\f[R], and may be set with colour\-named variables or raw
escape sequences (these must not change cursor position).
.SH CONFIGURATION AND CACHE FILES
User configuration is stored in \f[B]\[ti]/.chatgpt.conf\f[R].
Its path location can be set with envar \f[B]$CHATGPTRC\f[R].
.PP
The script cache directory is \f[B]\[ti]/.cache/chatgptsh/\f[R] and may
contain the following file types:
.IP \[bu] 2
\f[B]Session Records (tsv):\f[R] Tab\-separated value files storing
session history.
The default session record is \f[B]chatgpt.tsv\f[R].
.IP \[bu] 2
\f[B]Prompt Files (pr):\f[R] Files storing user\-defined custom
instructions (initial prompts).
.IP \[bu] 2
\f[B]Command History (history_bash):\f[R] Bash command\-line input
history.
This file is trimmed according to the \f[B]$HISTSIZE\f[R] setting in the
configuration file.
While it improves session recall, a large \f[B]history_bash\f[R] file
can slow down script startup.
It can be safely removed if necessary.
.IP \[bu] 2
\f[B]Temporary Buffers:\f[R] Various files holding temporary text and
data.
These files are safe to remove and are not intended for backup.
.PP
\f[B]Backup Recommendation:\f[R] It is strongly recommended to back up
session record files (tsv) and prompt files (pr), as well as the
configuration file (chatgpt.sh) to preserve session history, custom
promptsnd settings.
.SH KEYBINDINGS
Press <\f[I]CTRL\-X\f[R] \f[I]CTRL\-E\f[R]> to edit command line in text
editor from readline.
.PP
Press <\f[I]CTRL\-J\f[R]> or <\f[I]CTRL\-V\f[R] \f[I]CTRL\-J\f[R]> for
newline in readline.
.PP
Press <\f[I]CTRL\-L\f[R]> to redraw readline buffer (user input) on
screen.
.PP
During \f[I]cURL\f[R] requests, press <\f[I]CTRL\-C\f[R]> once to
interrupt the call.
.PP
Press <\f[I]CTRL\-\[rs]\f[R]> to exit from the script (send
\f[I]QUIT\f[R] signal), or \[lq]\f[I]Q\f[R]\[rq] in user confirmation
prompts.
.SH NOTES
Stdin text is appended to any existing command line PROMPT.
.PP
Input sequences \[lq]\f[I]\[rs]n\f[R]\[rq] and
\[lq]\f[I]\[rs]t\f[R]\[rq] are only treated specially (as escaped new
lines and tabs) in restart, start and stop sequences.
.PP
The moderation endpoint can be accessed by setting the model name to
\f[I]omni\-moderation\-latest\f[R] (or
\f[I]text\-moderation\-latest\f[R]).
.PP
For complete model and settings information, refer to OpenAI API docs at
\c
.UR https://platform.openai.com/docs/
.UE \c
\&.
.PP
See the online man page and \f[CR]chatgpt.sh\f[R] usage examples at: \c
.UR https://gitlab.com/fenixdragao/shellchatgpt
.UE \c
\&.
.SH REQUIRED PACKAGES
.IP \[bu] 2
\f[CR]Bash\f[R] shell
.IP \[bu] 2
\f[CR]cURL\f[R] and \f[CR]JQ\f[R]
.SH OPTIONAL PACKAGES
Optional packages for specific features.
.IP \[bu] 2
\f[CR]Base64\f[R] \- Image input in vision models
.IP \[bu] 2
\f[CR]Python\f[R] \- Modules tiktoken, markdown, bs4
.IP \[bu] 2
\f[CR]SoX\f[R]/\f[CR]Arecord\f[R]/\f[CR]FFmpeg\f[R] \- Record input
(STT, Whisper)
.IP \[bu] 2
\f[CR]mpv\f[R]/\f[CR]SoX\f[R]/\f[CR]Vlc\f[R]/\f[CR]FFplay\f[R]/\f[CR]afplay\f[R]
\- Play TTS output
.IP \[bu] 2
\f[CR]xdg\-open\f[R]/\f[CR]open\f[R]/\f[CR]xsel\f[R]/\f[CR]xclip\f[R]/\f[CR]pbcopy\f[R]
\- Open files, set clipboard
.IP \[bu] 2
\f[CR]W3M\f[R]/\f[CR]Lynx\f[R]/\f[CR]ELinks\f[R]/\f[CR]Links\f[R] \-
Dump URL text
.IP \[bu] 2
\f[CR]bat\f[R]/\f[CR]Pygmentize\f[R]/\f[CR]Glow\f[R]/\f[CR]mdcat\f[R]/\f[CR]mdless\f[R]
\- Markdown support
.IP \[bu] 2
\f[CR]termux\-api\f[R]/\f[CR]termux\-tools\f[R]/\f[CR]play\-audio\f[R]
\- Termux system
.IP \[bu] 2
\f[CR]poppler\f[R]/\f[CR]gs\f[R]/\f[CR]abiword\f[R]/\f[CR]ebook\-convert\f[R]/\f[CR]LibreOffice\f[R]
\- Dump PDF or Doc as text
.IP \[bu] 2
\f[CR]dialog\f[R]/\f[CR]kdialog\f[R]/\f[CR]zenity\f[R]/\f[CR]osascript\f[R]/\f[CR]termux\-dialog\f[R]
\- File picker
.IP \[bu] 2
\f[CR]yt\-dlp\f[R] \- Dump YouTube captions
.SH CAVEATS
The script objective is to implement some of the features of OpenAI API
version 1.
As text is the only universal interface, voice and image features will
only be partially supported, and not all endpoints or options will be
covered.
.PP
This project \f[I]does not support\f[R] \[lq]Function Calling\[rq],
\[lq]Structured Outputs\[rq], \[lq]Real\-Time Conversations\[rq],
\[lq]Agents/Operators\[rq], \[lq]MCP Servers\[rq], nor \[lq]video
generation / editing\[rq] capabilities.
.PP
Support for \[lq]Responses API\[rq] is limited and experimental at this
point.
.PP
Image generations, variations, and editing endpoints was dropped in
December\-2005 with script version v123.
.SH BUGS
Prompt caching may render (havoc) seemigly higher token counts recorded
in the local session history database due to cached tokens, e.g.\ xAI
reasoning models.
Service providers may actually inject (though not bill) certain amounts
of instruction\-like tokens automatically.
.PP
Reasoning (thinking) and answers from certain API services may not have
a distinct separation of output due to JSON processing constraints.
.PP
Bash \[lq]read command\[rq] may not correctly display input buffers
larger than the TTY screen size during editing.
However, input buffers remain unaffected.
Use the text editor interface for big prompt editing.
.PP
If readline screws up your current input buffer, try pressing
<\f[I]CTRL\-L\f[R]> to force it to redisplay and refresh the prompt
properly on screen.
.PP
File paths containing spaces may not work correctly in the chat
interface.
Make sure to backslash\-escape filepaths with white spaces.
.PP
Folding the response at white spaces may not worked correctly if the
user has changed his terminal tabstop setting.
Reset it with command \[lq]tabs \-8\[rq] or \[lq]reset\[rq] before
starting the script, or set one of these in the script configuration
file.
.PP
If folding does not work well at all, try exporting envar
\f[CR]$COLUMNS\f[R] before script execution.
.PP
Bash truncates input on \[lq]\[rs]000\[rq] (null).
.PP
Garbage in, garbage out.
An idiot savant.
.PP
The script logic resembles a bowl of spaghetti code after a cat fight.
.SH AUTHORS
mountaineerbr.
