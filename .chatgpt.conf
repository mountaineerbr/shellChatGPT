# ~/.chatgpt.conf
# Config file for chatgpt.sh v0.56.6
# Unset variables use defaults

# API keys
#OPENAI_API_KEY=
#GOOGLE_API_KEY=
#MISTRAL_API_KEY=

# DEFAULTS
# Text cmpls model
#MOD="gpt-3.5-turbo-instruct"

# Chat cmpls model
#MOD_CHAT="gpt-4-turbo"  #"gpt-4-turbo-2024-04-09"

# Image model (generations)
#MOD_IMAGE="dall-e-3"

# Whisper model (STT)
#MOD_AUDIO="whisper-1"

# Speech model (TTS)
#MOD_SPEECH="tts-1"  #"tts-1-hd"

# LocalAI model
#MOD_LOCALAI="phi-2"

# Ollama model
#MOD_OLLAMA="llama2"  #"llama2-uncensored:latest"

# Google AI model
#MOD_GOOGLE="gemini-1.0-pro-latest"

# Mistral AI model
#MOD_MISTRAL="mistral-large-latest"

# Bash readline mode
#READLINEOPT="emacs"  #"vi"

# Stream response
#STREAM=1

# Prompter flush with <CTRL-D>
#OPTCTRD=

# Temperature
#OPTT=0

# Top_p probability mass (nucleus sampling)
#OPTP=1

# Top_k (localai, ollama, google ai)
#OPTK=

# Maximum response tokens
#OPTMAX=1024

# Model capacity (auto)
#MODMAX=

# Presence penalty
#OPTA=

# Frequency penalty
#OPTAA=

# N responses of Best_of
#OPTB=

# Number of responses
#OPTN=1

# Keep Alive (seconds, Ollama)
#OPT_KEEPALIVE=

# Set python tiktoken
#OPTTIK=

# Text editor
#VISUAL="vim"

# Image size
#OPTS=1024x1024

# Image out format
#OPTI_FMT=b64_json  #url

# TTS voice
#OPTZ_VOICE=  #alloy, echo, fable, onyx, nova, and shimmer

# TTS voice speed
#OPTZ_SPEED=   #0.25 - 4.0

# TTS out format
#OPTZ_FMT=opus  #mp3, opus, aac, flac

# Recorder command, e.g. "sox -d"
#REC_CMD=""

# Media player command, e.g. "cvlc"
#PLAY_CMD=""

# CLipboard set command, e.g. "xsel -b", "pbcopy"
#CLIP_CMD=""

# Markdown renderer, e.g. "pygmentize -s -lmd", "glow", "mdless", "mdcat"
#MD_CMD="bat"

# Fold response (wrap at white spaces)
#OPTFOLD=1

# Inject restart text
# Chat mode of text cmpls sets "\nQ: "
#RESTART=""

# Inject start text
# Chat mode of text cmpls sets "\nA:"
#START=""


# INSTRUCTION (text/chat completions, and edits)
# * Instructions are very important to define character and personality for the language model. *
#
#INSTRUCTION=""
#
#INSTRUCTION_CHAT="A seguinte é uma conversa com um assistente de IA. O assistente é prestativo, criativo, inteligente e muito amigável."  #portuguese
#INSTRUCTION_CHAT="The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and friendly."


# CACHE AND OUTPUT DIRECTORIES
#CACHEDIR="$HOME/.cache/chatgptsh"
#OUTDIR="$HOME/Downloads"

# Host API URLs
#OPENAI_API_HOST_STATIC=""  #disable endpoint auto-selection
#OPENAI_API_HOST="https://api.openai.com"
#OLLAMA_API_HOST="http://localhost:11434"


# COLOR THEMES
# Theme defaults
#Color11="${BWhite}"    Color10="${White}"    # system, \e[1;37m
#Color9="${BCyan}"      Color8="${Cyan}"      # user input
#Color7="${On_Purple}"  Color6="${BPurple}"   Color5="${Purple}"  # whisper
#Color4="${BYellow}"    Color3="${Yellow}"    # response
#Color2="${BRed}"       Color1="${Red}"       # warning / error

# Theme 1
#Color11="${Red}" Color10="${BRed}" Color9="${Purple}" Color8="${BPurple}" Color7="${On_Cyan}" Color6="${Cyan}" Color5="${BCyan}" Color4="${Green}" Color3="${BGreen}" Color2="${Blue}" Color1="${BBlue}"

# Theme 2
#Color11="${BBlue}${On_White}" Color10="${Blue}${On_White}" Color9="${BRed}" Color8="${Red}" Color7="${BWhite}${On_Blue}" Color6="${BGreen}${On_Blue}" Color5="${Green}${On_Blue}" Color4="${BPurple}${On_Blue}" Color3="${Purple}${On_Blue}" Color2="${White}${On_Red}" Color1="${BWhite}${On_Red}"

# Theme 3.1
#Color11="${On_Purple}" Color10="${BWhite}${On_Purple}" Color9="${Blue}" Color8="${BBlue}" Color7="${On_Blue}" Color6="${BYellow}${On_Blue}" Color5="${Yellow}${On_Blue}" Color4="${BWhite}" Color3="${White}" Color2="${BWhite}${On_Red}" Color1="${On_Red}"
